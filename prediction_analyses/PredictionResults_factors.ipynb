{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a summary of the predictive analyses using task or survey data to predict a set of factors based on demographic/health measures.  \n",
    "\n",
    "#### Provenance:\n",
    "- data generated for each run using behav_prediction.py via Singularity container\n",
    "- multiple runs generated on lonestar5 using singularity_analyses/mk_singularity_script_factor.py\n",
    "- individual data files combined on ls5 using singularity_analyses/ls5/check_completion.py which generates singularity_analyses/ls5/lasso_data.pkl (which is copied to mac for next step)\n",
    "- data structures further collapsed using export_data_for_R_factor.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/rpy2/rinterface/_rinterface.cpython-36m-darwin.so, 2): Library not loaded: @rpath/libiconv.2.dylib\n  Referenced from: /Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/rpy2/rinterface/_rinterface.cpython-36m-darwin.so\n  Reason: Incompatible library version: _rinterface.cpython-36m-darwin.so requires version 9.0.0 or later, but libiconv.2.dylib provides version 8.0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-49c06994bfbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msandbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticomp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultipletests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext rpy2.ipython'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdendrogram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcut_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleaves_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-62>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
      "\u001b[0;32m/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_load_ipython_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/rpy2/ipython/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrmagic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_ipython_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# numpy and rpy2 imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrinterface\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobjects\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrpy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrpacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/rpy2/rinterface/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m from rpy2.rinterface._rinterface import (baseenv,\n\u001b[0m\u001b[1;32m     51\u001b[0m                                          \u001b[0memptyenv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                                          \u001b[0mendr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/rpy2/rinterface/_rinterface.cpython-36m-darwin.so, 2): Library not loaded: @rpath/libiconv.2.dylib\n  Referenced from: /Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/rpy2/rinterface/_rinterface.cpython-36m-darwin.so\n  Reason: Incompatible library version: _rinterface.cpython-36m-darwin.so requires version 9.0.0 or later, but libiconv.2.dylib provides version 8.0.0"
     ]
    }
   ],
   "source": [
    "import os,glob,sys\n",
    "import pickle\n",
    "import numpy,pandas\n",
    "pandas.options.display.max_colwidth = 0\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "%load_ext rpy2.ipython\n",
    "from scipy.cluster.hierarchy import dendrogram,ward,cut_tree,leaves_list\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import selfregulation.prediction.behavpredict as behavpredict\n",
    "from prediction_notebook_utils import get_pval, get_importances,get_importance_list,plotvars\n",
    "\n",
    "clf='lasso'\n",
    "acc,features=pickle.load(open('singularity_analyses/ls5/%s_data_collapsed.pkl'%clf,'rb'))\n",
    "cont_measure='r2' # use r^2 or MAE for non-binary variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all variables to make sure they have the correct number of observations (120), and create tables summarizing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "allvars={}\n",
    "datasets=[]\n",
    "for k in acc.keys():\n",
    "    if len(acc[k])==0:\n",
    "        print('no data for',k)\n",
    "        continue\n",
    "    datasets.append(k)\n",
    "    for v in acc[k][cont_measure]['scores_cv']:\n",
    "        if v=='tmp':\n",
    "            continue\n",
    "        allvars[v]=cont_measure\n",
    "        \n",
    "alldata={'r2':pandas.DataFrame(),'MAE':pandas.DataFrame(),\n",
    "        'r2_pval':pandas.DataFrame()}\n",
    "target_n={}\n",
    "goodcount={}\n",
    "for d in datasets:\n",
    "    if len(acc[k])==0:\n",
    "        print('no data for',k)\n",
    "        continue\n",
    "    \n",
    "    goodcount[d]={}\n",
    "    target_n[d]=120\n",
    "    examplefeature=list(features[d].keys())[0]\n",
    "    print(d,features[d][examplefeature].shape[1])\n",
    "\n",
    "    for v in acc[d]['r2']['scores_cv']:\n",
    "        if not v in acc[d][allvars[v]]['scores_cv']:\n",
    "            goodcount[d][v]=0\n",
    "        else:\n",
    "            goodcount[d][v]=numpy.isfinite(acc[d][allvars[v]]['scores_cv'][v]).sum()\n",
    "        if goodcount[d][v]<target_n[d]:\n",
    "            print(d,v,goodcount[d][v],features[d][v].shape[1])\n",
    "\n",
    "for v in allvars:\n",
    "    vars={}\n",
    "    for k in datasets:\n",
    "        if not 'r2' in acc[k]:\n",
    "            continue\n",
    "        vars[k]=acc[k]['r2']['scores_cv'].mean().T\n",
    "    df=pandas.DataFrame(vars,index=[v])\n",
    "    alldata['r2']=alldata['r2'].append(df)\n",
    "\n",
    "    vars={}\n",
    "    for k in datasets:\n",
    "        if not 'MAE' in acc[k]:\n",
    "            continue\n",
    "        vars[k]=acc[k]['MAE']['scores_cv'].mean().T\n",
    "    df=pandas.DataFrame(vars,index=[v])\n",
    "    alldata['MAE']=alldata['MAE'].append(df)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features['survey'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Compute p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NOTE: factors were exported from R in the wrong order\n",
    "# This dict renames them\n",
    "# This should be fixed in the final run\n",
    "\n",
    "\n",
    "def get_pval(target,null,allvars,datasets,acc,verbose=False):\n",
    "    data=[]\n",
    "    vars=[i for i in list(allvars.keys()) if not i=='tmp']\n",
    "    vars.sort()\n",
    "    for v in vars:\n",
    "        if verbose:\n",
    "            print(target,null,v)\n",
    "        if not v in acc[target][allvars[v]]['scores_cv'] or not v in acc[null][allvars[v]]['scores_cv']:\n",
    "            data.append([allvars[v],numpy.nan,numpy.nan,numpy.nan,numpy.nan,numpy.nan])\n",
    "            continue\n",
    "        targdist=acc[target][allvars[v]]['scores_cv'][v].dropna()\n",
    "        targmean=targdist.mean()\n",
    "        nulldist=acc[null][allvars[v]]['scores_cv'][v].dropna()\n",
    "        nullmean=nulldist.mean()\n",
    "        targstd=targdist.std()\n",
    "        pval=1-scipy.stats.percentileofscore(nulldist,targmean)/100.\n",
    "        if targstd>0:\n",
    "            #es=(targmean-nullmean)/targstd\n",
    "            es=targmean-nullmean\n",
    "        else:\n",
    "            es=numpy.nan\n",
    "        insample=acc[target][allvars[v]]['scores_insample_unbiased'][v].mean()\n",
    "        data.append([allvars[v],targmean,nullmean,es,insample,pval])\n",
    "    #newvars=[factor_renaming_dict[i] for i in vars]\n",
    "    df=pandas.DataFrame(data,index=vars,columns=['Measure','Target mean','Null Mean','Effect size','In-sample','p_unc'])\n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "pvals={}\n",
    "for d in datasets:\n",
    "    if d.find('shuffle')>-1 or len(acc[d])==0:\n",
    "        continue\n",
    "    print(d)\n",
    "    pvals[(d,d+'_shuffle')]=get_pval(d,d+'_shuffle',allvars,datasets,acc)\n",
    "\n",
    "pvals_fdr={}\n",
    "for k in pvals:\n",
    "    tmp=multipletests(pvals[k]['p_unc'])\n",
    "    pvals[k]['p_fdr']=tmp[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=('survey','survey_shuffle')\n",
    "plt.figure(figsize=(8,8))\n",
    "r2data=pvals[k].query('Measure == \"r2\"')\n",
    "plt.scatter(r2data['Target mean'],r2data['In-sample'])\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.axis([0,0.1,0,0.1])\n",
    "plt.xlabel('Out-of-sample R^2',fontsize=20)\n",
    "plt.ylabel('In-sample R^2',fontsize=20)\n",
    "plt.savefig('overfitting.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variables with greater prediction for survey vs. baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pthresh=0.05\n",
    "sigp={}\n",
    "plot_sep_vars=False\n",
    "k=('survey','survey_shuffle')\n",
    "sigp[k]=pvals[k].query('p_fdr <= %f'% pthresh).sort_values(by='Effect size',ascending=False)\n",
    "imp=get_importance_list(sigp[k],k[0],features)\n",
    "sigp[k]=sigp[k].join(imp)\n",
    "display(sigp[k])\n",
    "if plot_sep_vars:\n",
    "    for v in sigp[k].index:\n",
    "        plotvars(v,pvals,datasets,allvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=('survey','survey_shuffle')\n",
    "for i in sigp[k].index:\n",
    "    print(i,get_importances(i,k[0],features,10))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variables with greater prediction for task vs. baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k=('task','task_shuffle')\n",
    "sigp[k]=pvals[k].query('p_fdr <= %f'% pthresh).sort_values(by='Effect size',ascending=False)\n",
    "imp=get_importance_list(sigp[k],k[0],features)\n",
    "sigp[k]=sigp[k].join(imp)\n",
    "display(sigp[k])\n",
    "if plot_sep_vars:\n",
    "    for v in sigp[k].index:\n",
    "        plotvars(v,pvals,datasets,allvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=('task','task_shuffle')\n",
    "for i in sigp[k].index:\n",
    "    print(i,get_importances(i,k[0],features))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pvals[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make figure for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_paper_vars(vars,pvals,datasets,allvars):\n",
    "    f, axarr = plt.subplots(2, 2,figsize=(18,16))\n",
    "    xy=[[0,0],[0,1],[1,0],[1,1]]\n",
    "    ctr=0\n",
    "    for v in vars:\n",
    "        df=[]\n",
    "        errors=[]\n",
    "        ds=[]\n",
    "        for k in datasets:\n",
    "            if not allvars[v] in acc[k]:\n",
    "                continue\n",
    "            if not v in acc[k][allvars[v]]['scores_cv']:\n",
    "                continue\n",
    "            targdist=acc[k][allvars[v]]['scores_cv'][v].dropna()\n",
    "            df.append(targdist.mean())\n",
    "            ds.append(k)\n",
    "            errors.append(targdist.std())\n",
    "        df=pandas.DataFrame({'mean':df},index=ds)\n",
    "        errors=pandas.DataFrame({'mean':errors},index=ds)\n",
    "        if allvars[v]=='AUROC':\n",
    "            df.plot.bar(yerr=errors,legend=False,\n",
    "                    ylim=(0.45,numpy.max(df.values)*1.1),\n",
    "                        ax=axarr[xy[ctr][0],xy[ctr][1]],\n",
    "                       title=v)\n",
    "        else:\n",
    "            df.plot.bar(yerr=errors,legend=False,\n",
    "                        ax=axarr[xy[ctr][0],xy[ctr][1]],\n",
    "                       title=v)\n",
    "        if xy[ctr][0]==0:\n",
    "            x_axis = axarr[xy[ctr][0],xy[ctr][1]].axes.get_xaxis()\n",
    "            x_axis.set_visible(False)\n",
    "        if xy[ctr][1]==0:\n",
    "            plt.ylabel(allvars[v]+' +/- SE across CV runs')\n",
    "        ctr+=1\n",
    "                                                                  \n",
    "vars=list(pvals[('survey','survey_shuffle')].index)       \n",
    "#def plot_paper_vars2(vars,pvals,datasets,allvars):\n",
    "if 1:\n",
    "    f= plt.figure(figsize=(18,12))\n",
    "    ax=plt.gca()\n",
    "    data=None\n",
    "    errors=None\n",
    "    for v in vars:\n",
    "        df=[]\n",
    "        err=[]\n",
    "        ds=[]\n",
    "        for k in datasets:\n",
    "            if k.find('_shuffle')>-1:\n",
    "                continue\n",
    "            if not allvars[v] in acc[k]:\n",
    "                continue\n",
    "            if not v in acc[k][allvars[v]]['scores_cv']:\n",
    "                continue\n",
    "            targdist=acc[k][allvars[v]]['scores_cv'][v].dropna()\n",
    "            df.append(targdist.mean())\n",
    "            ds.append(k)\n",
    "            err.append(targdist.std())\n",
    "        if data is None:\n",
    "            data=pandas.DataFrame({v:df},index=ds)\n",
    "            errors=pandas.DataFrame({v:err},index=ds)\n",
    "        else:\n",
    "            data[v]=pandas.DataFrame({v:df},index=ds)\n",
    "            errors[v]=pandas.DataFrame({v:err},index=ds)\n",
    "            \n",
    "    if allvars[v]=='AUROC':\n",
    "        data.plot.bar(yerr=errors,legend=True,\n",
    "                ylim=(0.45,numpy.max(df.values)*1.1),\n",
    "                   title=v,ax=ax,fontsize=20)\n",
    "    else:\n",
    "        data.plot.bar(yerr=errors,\n",
    "                   ax=ax,fontsize=20)\n",
    "    plt.ylabel('R-squared +/- SE across CV runs',fontsize=20)\n",
    "    plt.legend(fontsize=20)                               \n",
    "\n",
    "#plot_paper_vars(figurevars,pvals,datasets,allvars)\n",
    "plt.savefig('barplots.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variables with greater prediction for DDM parameters vs. baseline\n",
    "\n",
    "### drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k=('drift','drift_shuffle')\n",
    "sigp[k]=pvals[k].query('p_fdr <= %f'% pthresh).sort_values(by='Effect size',ascending=False)\n",
    "imp=get_importance_list(sigp[k],k[0],features)\n",
    "sigp[k]=sigp[k].join(imp)\n",
    "display(sigp[k])\n",
    "for v in sigp[k].index:\n",
    "    plotvars(v,pvals,datasets,allvars)\n",
    "    print(v)\n",
    "    print(get_importances(v,k[0],features)  )  \n",
    "    print('')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=('thresh','thresh_shuffle')\n",
    "sigp[k]=pvals[k].query('p_fdr <= %f'% pthresh).sort_values(by='Effect size',ascending=False)\n",
    "imp=get_importance_list(sigp[k],k[0],features)\n",
    "sigp[k]=sigp[k].join(imp)\n",
    "display(sigp[k])\n",
    "for v in sigp[k].index:\n",
    "    plotvars(v,pvals,datasets,allvars)\n",
    "    print(v)\n",
    "    print(get_importances(v,k[0],features)  )  \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nondecision time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=('nondecision','nondecision_shuffle')\n",
    "sigp[k]=pvals[k].query('p_fdr <= %f'% pthresh).sort_values(by='Effect size',ascending=False)\n",
    "imp=get_importance_list(sigp[k],k[0],features)\n",
    "sigp[k]=sigp[k].join(imp)\n",
    "display(sigp[k])\n",
    "for v in sigp[k].index:\n",
    "    plotvars(v,pvals,datasets,allvars)\n",
    "    print(v)\n",
    "    print(get_importances(v,k[0],features)  )  \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variables with greater prediction for intelligence vs. baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=('intelligence','intelligence_shuffle')\n",
    "sigp[k]=pvals[k].query('p_fdr <= %f'% pthresh).sort_values(by='Effect size',ascending=False)\n",
    "imp=get_importance_list(sigp[k],k[0],features)\n",
    "sigp[k]=sigp[k].join(imp)\n",
    "display(sigp[k])\n",
    "for v in sigp[k].index:\n",
    "    plotvars(v,pvals,datasets,allvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variables with greater prediction for stopping vs. baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=('stopping','stopping_shuffle')\n",
    "sigp[k]=pvals[k].query('p_fdr <= %f'% pthresh).sort_values(by='Effect size',ascending=False)\n",
    "imp=get_importance_list(sigp[k],k[0],features)\n",
    "sigp[k]=sigp[k].join(imp)\n",
    "display(sigp[k])\n",
    "for v in sigp[k].index:\n",
    "    plotvars(v,pvals,datasets,allvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show variables with greater prediction for discounting vs. baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=('discounting','discounting_shuffle')\n",
    "sigp[k]=pvals[k].query('p_fdr <= %f'% pthresh).sort_values(by='Effect size',ascending=False)\n",
    "imp=get_importance_list(sigp[k],k[0],features)\n",
    "sigp[k]=sigp[k].join(imp)\n",
    "display(sigp[k])\n",
    "for v in sigp[k].index:\n",
    "    plotvars(v,pvals,datasets,allvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess survey variables in terms of their overall predictive utility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k=('survey','baseline')\n",
    "df=pandas.DataFrame()\n",
    "absfeat=pandas.DataFrame()\n",
    "\n",
    "for v in features['survey']:\n",
    "    df[v]=features['survey'][v].mean(0)\n",
    "    absfeat[v]=(features['survey'][v].abs()>0).mean()\n",
    "    \n",
    "mean_imp=df.mean(1)\n",
    "meanabs_survey=pandas.DataFrame({'meanabs':absfeat.mean(1)}).sort_values(by='meanabs',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pandas.DataFrame()\n",
    "absfeat=pandas.DataFrame()\n",
    "\n",
    "for v in features['task']:\n",
    "    df[v]=features['task'][v].mean(0)\n",
    "    absfeat[v]=(features['task'][v].abs()>0).mean()\n",
    "    \n",
    "mean_imp=df.mean(1)\n",
    "meanabs_task=pandas.DataFrame({'meanabs':absfeat.mean(1)}).sort_values(by='meanabs',ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize structure of demographic target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bp=behavpredict.BehavPredict(verbose=True,\n",
    "     drop_na_thresh=100,\n",
    "     skip_vars=['RetirementPercentStocks',\n",
    "     'HowOftenFailedActivitiesDrinking',\n",
    "     'HowOftenGuiltRemorseDrinking',\n",
    "     'AlcoholHowOften6Drinks'],\n",
    "     add_baseline_vars=True,\n",
    "     freq_threshold=0.1)\n",
    "bp.load_demog_data()\n",
    "bp.get_demogdata_vartypes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demogdata=bp.demogdata.copy()\n",
    "for i in demogdata.columns:\n",
    "    if not i in features['task'] and not i in features['survey']:\n",
    "        del demogdata[i]\n",
    "        print('removing',i)\n",
    "demogdata=demogdata.T\n",
    "demogdata['goodvar']=demogdata.isnull().sum(1)<10\n",
    "demogdata_clean=demogdata.query('goodvar==True')\n",
    "print(demogdata.shape)\n",
    "del demogdata_clean['goodvar']\n",
    "demogdata_clean=demogdata_clean.T\n",
    "\n",
    "# these are bad vars that don't have features\n",
    "dropvars=['HowOftenCantStopDrinking',\n",
    "'HowOftenFailedActivitiesDrinking',\n",
    "'HowOftenGuiltRemorseDrinking','AlcoholHowOften6Drinks']\n",
    "\n",
    "for v in dropvars:\n",
    "    if v in demogdata_clean:\n",
    "        del demogdata_clean[v]\n",
    "        print('removing',v)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from fancyimpute import SimpleFill\n",
    "\n",
    "def residualize_baseline(df):\n",
    "    # remove baseline vars\n",
    "    baseline=df[['Age','Sex']]\n",
    "    data=df.copy()\n",
    "    del data['Age']\n",
    "    del data['Sex']\n",
    "    #x=SimpleFill().complete(baseline)\n",
    "    lr=LinearRegression()\n",
    "    for v in data:\n",
    "        #print('residualizing',v)\n",
    "        if data[v].isnull().sum()>0:\n",
    "            y=SimpleFill().complete(data[v].values[:,numpy.newaxis])\n",
    "        else:\n",
    "            y=data[v]\n",
    "        lr.fit(baseline,y)\n",
    "        data[v]=y - lr.predict(baseline)\n",
    "    return data\n",
    "df_resid=residualize_baseline(demogdata_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dthresh=2.0\n",
    "dist=1-numpy.abs(df_resid.corr(method='spearman'))\n",
    "k=ward(numpy.triu(dist))\n",
    "c=cut_tree(k,height=dthresh)\n",
    "ll=leaves_list(k)\n",
    "\n",
    "matches={}\n",
    "matchnums={}\n",
    "clustdict={}\n",
    "for i in numpy.unique(c):\n",
    "    matches[i]=[]\n",
    "    matchnums[i]=[]\n",
    "    for j in numpy.where(c==i)[0]:\n",
    "        matches[i].append(df_resid.columns[j])\n",
    "        clustdict[df_resid.columns[j]]=i\n",
    "        matchnums[i].append(j)\n",
    "\n",
    "matchdesc={0:'education/height/weight',1:'relationships',2:'domestic',3:'financial/coffee',\n",
    "          4:'caffeine',5:'legal problems',6:'smoking',7:'alcohol use',\n",
    "          8:'alcohol/drug problems',9:'mental health',10:'obesity'}\n",
    "\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get top predictive features for each cluster\n",
    "impdata={}\n",
    "binarize_features=True\n",
    "feature_thresh=1e-5\n",
    "for i in matchdesc.keys():\n",
    "    print(matchdesc[i])\n",
    "    print(matches[i])\n",
    "    df_subset=df_resid\n",
    "\n",
    "    df_tmp=pandas.DataFrame()\n",
    "    absfeat_tmp=pandas.DataFrame()\n",
    "\n",
    "    for v in matches[i]:\n",
    "        # drop variables that don't have features for both task and survey\n",
    "        if not v in features['task'] or not v in features['survey']:\n",
    "            print('ooop',v)\n",
    "            continue\n",
    "        minsize=numpy.min([features['survey'][v].shape[0],features['task'][v].shape[0]]).astype('int')\n",
    "        sfeatures=features['survey'][v].copy()\n",
    "        sfeatures=sfeatures.iloc[:minsize,:]\n",
    "        #print(sfeatures.shape)\n",
    "        tfeatures=features['task'][v].copy()\n",
    "        tfeatures=tfeatures.iloc[:minsize,:]\n",
    "        #print(tfeatures.shape)\n",
    "        all_features=pandas.concat([sfeatures,tfeatures],axis=1) #sfeatures.join(tfeatures)\n",
    "        if binarize_features:\n",
    "            all_features[all_features>feature_thresh]=1\n",
    "            all_features[all_features<-1*feature_thresh]=-1\n",
    "\n",
    "        del all_features['Sex']\n",
    "        del all_features['Age']\n",
    "        df_tmp[v]=all_features.mean(0)\n",
    "        absfeat_tmp[v]=(all_features.abs()>0).mean(0)\n",
    "\n",
    "    mean_imp=pandas.DataFrame({'meanimp':df_tmp.mean(1),\n",
    "                               'meanabs':absfeat_tmp.mean(1)})\n",
    "    impdata[i]=mean_imp.sort_values(by='meanabs',ascending=False)\n",
    "\n",
    " \n",
    "    display(impdata[i].iloc[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(14,12))\n",
    "plt.subplot(1,2,1)\n",
    "d=dendrogram(k,orientation='left',\n",
    "             labels=list(df_resid.T.index),\n",
    "             color_threshold=dthresh,leaf_font_size=12)\n",
    "plt.plot([dthresh,dthresh],[0,500],'k--')\n",
    "\n",
    "omult=10\n",
    "breaks=[]\n",
    "\n",
    "for i in range(len(d['ivl'])):\n",
    "    if i>0:\n",
    "        if clustdict[d['ivl'][i]]==clustdict[d['ivl'][i-1]]:\n",
    "            continue\n",
    "    #print(clustdict[d['ivl'][i]],clustdict[d['ivl'][i-1]])\n",
    "    breaks.append(i)\n",
    "breaks.append(len(d['ivl']))\n",
    "replace_sets=[('.',':'),('_',' '),('selection optimization compensation','SOC'),\n",
    "             ('theories of ','')]\n",
    "\n",
    "for i in range(1,len(breaks)):\n",
    "    plt.plot([0,20],[breaks[i]*omult,breaks[i]*omult],'k--',linewidth=0.5)\n",
    "    if numpy.sum(impdata[clustdict[d['ivl'][breaks[i-1]]]]['meanabs']==1)>2:\n",
    "        nfeats=numpy.sum(impdata[clustdict[d['ivl'][breaks[i-1]]]]['meanabs']==1).astype('int')\n",
    "    else:\n",
    "        nfeats=2\n",
    "    for j in range(nfeats):\n",
    "        vartitle=impdata[clustdict[d['ivl'][breaks[i-1]]]].index[j]\n",
    "        for r in replace_sets:\n",
    "            vartitle=vartitle.replace(r[0],r[1])\n",
    "        plt.text(-11.5,0.5*(breaks[i]+breaks[i-1])*omult-j*8+nfeats,\n",
    "             '%s (%0.2f/%0.2f)'%(vartitle,\n",
    "                       impdata[clustdict[d['ivl'][breaks[i-1]]]]['meanimp'][j],\n",
    "                        impdata[clustdict[d['ivl'][breaks[i-1]]]]['meanabs'][j]))\n",
    "    plt.text(14,0.5*(breaks[i]+breaks[i-1])*omult-4+nfeats,\n",
    "             matchdesc[clustdict[d['ivl'][breaks[i-1]]]],fontsize=12)\n",
    "\n",
    "plt.savefig('dendrogram.png',dpi=300,pad_inches=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering on predictor loadings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks pretty crappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "surveyfiles=glob.glob('/Users/poldrack/code/Self_Regulation_Ontology/prediction_analyses/R_exports_lasso/features/survey*')\n",
    "dropvars=['Age','Sex']\n",
    "loadingdata={'survey':None}\n",
    "include_task=False\n",
    "\n",
    "for f in surveyfiles:\n",
    "    varname=f.split('survey')[1].split('_')[1]\n",
    "    for d in dropvars:\n",
    "        if f.find(d)>-1:\n",
    "            continue\n",
    "    sdata=pandas.read_csv(f).mean(0)\n",
    "    if include_task:\n",
    "        tf=f.replace('features/survey_','features/task_')\n",
    "        if not os.path.exists(tf):\n",
    "            print('skipping',varname)\n",
    "            continue\n",
    "        tdata=pandas.read_csv(tf).mean(0)\n",
    "        alldata=pandas.concat((tdata,sdata))\n",
    "    else:\n",
    "        alldata=sdata\n",
    "    if loadingdata['survey'] is None:\n",
    "        loadingdata['survey']=pandas.DataFrame({varname:alldata})\n",
    "    else:\n",
    "        loadingdata['survey'][varname]=alldata\n",
    "        \n",
    "loadingdata['survey']=loadingdata['survey'].drop('Age').drop('Sex')\n",
    "del loadingdata['survey']['Age']\n",
    "del loadingdata['survey']['Sex']\n",
    "allvars=[i for i in list(loadingdata['survey'].columns) if not i.find('.binarized')>-1]\n",
    "for c in allvars:\n",
    "    if '%s.binarized'%c in loadingdata['survey']:\n",
    "        del loadingdata['survey']['%s.binarized'%c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist=1-loadingdata['survey'].corr(method='spearman')\n",
    "k=ward(numpy.triu(dist))\n",
    "c=cut_tree(k,height=dthresh)\n",
    "ll=leaves_list(k)\n",
    "\n",
    "fig=plt.figure(figsize=(14,12))\n",
    "plt.subplot(1,2,1)\n",
    "d=dendrogram(k,orientation='left',\n",
    "             labels=list(loadingdata['survey'].T.index),\n",
    "             color_threshold=dthresh,leaf_font_size=12)\n",
    "\n",
    "matches={}\n",
    "matchnums={}\n",
    "clustdict={}\n",
    "for i in numpy.unique(c):\n",
    "    matches[i]=[]\n",
    "    matchnums[i]=[]\n",
    "    for j in numpy.where(c==i)[0]:\n",
    "        matches[i].append(loadingdata['survey'].columns[j])\n",
    "        clustdict[loadingdata['survey'].columns[j]]=i\n",
    "        matchnums[i].append(j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task-specific prediction analyses - for Aim 2 task selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tasks=['attention_network_task', \n",
    "       'columbia_card_task_hot', 'discount_titrate', \n",
    "       'dot_pattern_expectancy',\n",
    "       'kirby', 'motor_selective_stop_signal', 'stop_signal', \n",
    "       'stroop', \n",
    "       'threebytwo', 'tower_of_london']\n",
    "\n",
    "for t in tasks:\n",
    "    k=(t,t+'_shuffle')\n",
    "    if not k in pvals:\n",
    "        print('skipping',k)\n",
    "        continue\n",
    "    sigp[k]=pvals[k].query('p_unc <= %f'% pthresh).sort_values(by='Effect size',ascending=False)\n",
    "    imp=get_importance_list(sigp[k],k[0],features)\n",
    "    sigp[k]=sigp[k].join(imp)\n",
    "    display(sigp[k])\n",
    "    #for v in sigp[k].index:\n",
    "        #plotvars(v,pvals,datasets,allvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor analysis on outcome measures \n",
    "Exploratory - don't use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R -i df_resid -o scores,loadings,varnames\n",
    "\n",
    "\n",
    "dropvars <- names(df_resid) %in% c(\"HeightInches\", \"WeightPounds\", \"CigsPerDay\") \n",
    "print(dropvars)\n",
    "df <- df_resid[,!dropvars]\n",
    "\n",
    "\n",
    "library(psych)\n",
    "vss.result=VSS(df,16,fm='mle',plot=FALSE)\n",
    "#print(vss.result)\n",
    "nfactor=which.min(vss.result$vss.stats$BIC)\n",
    "fa.result=fa(df,nfactors=nfactor,fm='mle')\n",
    "loadings=fa.result$loadings\n",
    "print(fa.result,cut=0.2,sort=TRUE)\n",
    "scores=factor.scores(df,fa.result,method='tenBerge')$scores\n",
    "#clst=iclust(df_resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_df=pandas.DataFrame(scores,columns=['smoking severity','mental illness',\n",
    "                                           'smoking','obesity',\n",
    "                                           'alcohol','domestic'],index=df_resid.index)\n",
    "scores_df.to_csv(\"../Data/Derived_Data/Complete_10-08-2017/factor_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
